# LLM + Vector DB 기반 코드 리뷰 자동화 시스템

본 프로젝트는 코드 리뷰 효율성과 코드 품질 향상을 위해 대규모 언어 모델(LLM)과  
벡터 데이터베이스(Vector DB)를 활용하여 자동으로 코드 리뷰를 생성하는 시스템입니다.

이 시스템은 GitHub Pull Request와 연동하여 반복적이고 수동적인 코드 리뷰 작업을 자동화하고,  
팀 내 코드 컨벤션을 일관되게 적용하는 것을 목표로 하고 있습니다.

---

## 1. 전체 워크플로우 개요

이 시스템은 다음과 같은 목표를 기반으로 설계되었습니다.

- 코드 컨벤션 문서를 벡터 DB에 저장하여 규칙 기반 검색을 가능하게 함  
- PR에서 변경된 코드를 임베딩하여 유사한 규칙을 자동 조회  
- 조회한 규칙과 변경된 코드를 비교하여 LLM이 자동 리뷰 생성  
- 생성된 리뷰를 PR 코멘트 또는 내부 도구에 자동 기록  

### 전체 흐름

1. 컨벤션 문서를 Qdrant(Vector DB)에 저장  
2. 코드/PR 입력 발생  
3. 입력된 코드 임베딩 생성  
4. 벡터 DB에서 유사 규칙 검색  
5. LLM이 규칙과 코드를 비교하여 리뷰 생성  
6. 리뷰를 PR 코멘트 또는 시스템에 기록  

---

## 2. 컨벤션 기반 자동 리뷰가 필요한 이유

일반적인 코드 리뷰에는 다음과 같은 반복 작업이 포함됩니다.

- 네이밍 규칙 준수 여부  
- 매직 넘버 사용 여부  
- 테스트 코드의 구조적 명확성  
- Null/Optional 처리 방식  
- 중첩 로직 및 구조 개선 가능성  
- 계층 구조 및 설계 규칙 준수 여부  

이러한 작업은 리뷰마다 반복적으로 발생하며 시간이 많이 소요됩니다.  
컨벤션 기반 자동 리뷰 시스템을 통해 다음과 같은 효과를 기대할 수 있습니다.

- 리뷰 품질의 일관성 유지  
- 반복적인 리뷰 요소 자동화  
- 리뷰어는 복잡한 비즈니스 로직 검토에 집중 가능  

---

## 3. 시스템 구성 요소 상세

### 3.1 컨벤션 문서 정리 및 벡터화

팀 내부의 코드 컨벤션을 정리한 뒤, 각 규칙을 벡터 임베딩하여 Qdrant에 저장합니다.

예시 규칙:

- 클래스 이름은 UpperCamelCase로 작성합니다.  
- 메서드 이름은 동사로 시작하고 camelCase로 작성합니다.  
- 하드코딩된 값은 상수로 분리합니다.  
- Null 대신 Optional을 반환하는 것을 권장합니다.  
- 중첩된 if 문은 최소화합니다.

### 3.2 코드 임베딩 생성

PR이 생성되면 diff 또는 전체 파일을 가져와 코드 블록 단위로 임베딩을 생성합니다.

임베딩 모델 예:

- OpenAI text-embedding-3-small  
- Cohere Embed  
- CodeBERT / CodeT5 (온프레미스 가능)  

### 3.3 벡터 DB에서 유사 규칙 검색

생성된 코드 임베딩을 기반으로 Qdrant에 질의하여 유사도 Top-k 규칙을 검색합니다.

예시:

매직 넘버가 포함된 코드 → "매직 넘버는 static final 상수로 분리해야 합니다" 규칙과 높은 유사도로 매칭

### 3.4 LLM 기반 리뷰 생성

LLM에게 다음 정보를 전달합니다.

- 검색된 규칙 목록  
- 변경된 코드  
- 리뷰 목적  
- 출력 포맷  

LLM은 해당 규칙과 코드를 비교하여 리뷰 코멘트를 자동 생성합니다.

### 3.5 리뷰 결과 출력

생성된 리뷰는 다음과 같은 경로로 전달될 수 있습니다.

- GitHub Pull Request 코멘트 자동 등록  
- Slack, Notion 등 내부 시스템으로 연동  
- 사내 대시보드 구성  

---

## 4. 리뷰 결과 예시

자동 생성된 리뷰 예시는 다음과 같습니다.

1. 테스트 메서드 이름이 길고 복잡하므로, 더 간결하고 의미 있는 네이밍을 사용하는 것이 좋습니다.  
2. Null 대신 Optional을 사용하는 것이 컨벤션에 더 적합합니다.  
3. 매직 넘버 또는 하드코딩된 문자열을 상수로 분리하는 것이 좋습니다.  
4. @DisplayName을 적절히 사용하여 테스트의 가독성이 좋습니다.

이와 같이 LLM은 단순 정적 분석이 아니라 팀의 컨벤션을 기반으로 맥락 있는 리뷰를 제공합니다.

---

## 5. 기술 스택

| 구성 요소 | 기술 |
|----------|-------|
| 코드 임베딩 | OpenAI, Cohere, CodeBERT |
| Vector DB | Qdrant, Pinecone, PGVector |
| 리뷰 생성 | GPT-4, Claude, Ollama |
| 서버 구성 | Spring Boot, FastAPI, Spring AI |
| 자동화 트리거 | GitHub Webhook, GitHub Actions |
| 리뷰 출력 | PR 코멘트, Markdown, 내부 시스템 |

---

## 6. 시스템 한계 및 개선 방향

### 한계점

- 전체 처리 시간 지연 (약 6분 소요)  
- 임베딩/LLM 호출/DB 검색 등 리소스 사용량 증가  
- PR이 많은 환경에서는 운영 부담 증가  

### 개선 가능성

- 코드 블록 분할 및 병렬 처리  
- 임베딩 캐싱  
- diff 기반 최소 임베딩  
- GPU 기반 온프레미스 LLM/임베딩 서버 도입 (Ollama, vLLM)  
- 규칙 데이터 정규화 및 구조화  

